# üìä Experimento de An√°lise de Estruturas de Dados

## Objetivo do Experimento

Este experimento foi desenvolvido para realizar uma an√°lise comparativa abrangente de diferentes estruturas de dados, medindo sua performance em opera√ß√µes fundamentais (inser√ß√£o, busca e remo√ßüìä Configura√ß√£o do experimento:
  - 12 estruturas diferentes
  - 1 AVL Tree
  - 9 Hash Tables: 3 tamanhos (M=50,100,150) √ó 3 fun√ß√µes hash (poly31,fnv1a,djb2)
  - 2 Array Linked Lists (ordenada e n√£o-ordenada)
  - [1000, 2000, 3000, 4000, 5000, 6000, 7000, 8000, 9000, 10000]
  - 5 rounds por configura√ß√£o
  - Total: 600 execu√ß√µes

üîß ESTRUTURA 1/12: AVL Treeav√©s de m√∫ltiplas m√©tricas quantitativas.

## Metodologia Experimental

### Estruturas de Dados Analisadas

O experimento analisa **12 estruturas de dados diferentes**:

1. **AVL Tree** (`AVLTreeDS`)
   - √Årvore bin√°ria balanceada automaticamente
   - Garante altura logar√≠tmica para todas as opera√ß√µes

2. **Hash Table M=50 poly31** (`HashTableDS(M=50, hash_fn='poly31')`)
   - Fun√ß√£o hash polinomial com base 31
   - Tabela pequena para an√°lise de colis√µes
   - Usa encadeamento separado (chaining) para resolu√ß√£o de colis√µes

3. **Hash Table M=100 poly31** (`HashTableDS(M=100, hash_fn='poly31')`)
   - Fun√ß√£o hash polinomial com base 31
   - Tamanho m√©dio para compara√ß√£o
   - Usa encadeamento separado (chaining) para resolu√ß√£o de colis√µes

4. **Hash Table M=150 poly31** (`HashTableDS(M=150, hash_fn='poly31')`)
   - Fun√ß√£o hash polinomial com base 31
   - Tabela grande para reduzir colis√µes
   - Usa encadeamento separado (chaining) para resolu√ß√£o de colis√µes

5. **Hash Table M=50 fnv1a** (`HashTableDS(M=50, hash_fn='fnv1a')`)
   - Fun√ß√£o hash FNV-1a (Fowler‚ÄìNoll‚ÄìVo)
   - Tabela pequena com hash otimizado
   - Usa encadeamento separado (chaining) para resolu√ß√£o de colis√µes

6. **Hash Table M=100 fnv1a** (`HashTableDS(M=100, hash_fn='fnv1a')`)
   - Fun√ß√£o hash FNV-1a (Fowler‚ÄìNoll‚ÄìVo)
   - Tamanho m√©dio para compara√ß√£o
   - Usa encadeamento separado (chaining) para resolu√ß√£o de colis√µes

7. **Hash Table M=150 fnv1a** (`HashTableDS(M=150, hash_fn='fnv1a')`)
   - Fun√ß√£o hash FNV-1a (Fowler‚ÄìNoll‚ÄìVo)
   - Tabela grande para an√°lise de performance
   - Usa encadeamento separado (chaining) para resolu√ß√£o de colis√µes

8. **Hash Table M=50 djb2** (`HashTableDS(M=50, hash_fn='djb2')`)
   - Fun√ß√£o hash DJB2 de Dan J. Bernstein
   - Tabela pequena com hash amplamente usado
   - Usa encadeamento separado (chaining) para resolu√ß√£o de colis√µes

9. **Hash Table M=100 djb2** (`HashTableDS(M=100, hash_fn='djb2')`)
   - Fun√ß√£o hash DJB2 de Dan J. Bernstein
   - Tamanho m√©dio para compara√ß√£o
   - Usa encadeamento separado (chaining) para resolu√ß√£o de colis√µes

10. **Hash Table M=150 djb2** (`HashTableDS(M=150, hash_fn='djb2')`)
    - Fun√ß√£o hash DJB2 de Dan J. Bernstein
    - Tabela grande para an√°lise de performance
    - Usa encadeamento separado (chaining) para resolu√ß√£o de colis√µes

11. **Array Linked List N√£o-Ordenada** (`ArrayLinkedList()`)
    - Lista ligada implementada com arrays
    - Inser√ß√£o sempre no final, busca sequencial

12. **Array Linked List Ordenada** (`ArrayLinkedList(sorted_insert=True)`)
    - Lista ligada com inser√ß√£o ordenada
    - Busca mais eficiente, inser√ß√£o mais custosa

**Importante**: Todas as Hash Tables usam **encadeamento separado (chaining)** para resolu√ß√£o de colis√µes. Cada posi√ß√£o da tabela hash cont√©m uma lista ligada que pode armazenar m√∫ltiplos elementos quando ocorrem colis√µes.

### üìè Par√¢metros do Experimento

- **Tamanhos testados**: 1.000, 2.000, 3.000, ..., 10.000 elementos
- **Rounds por configura√ß√£o**: 5 execu√ß√µes independentes
- **Total de execu√ß√µes**: 600 (12 estruturas √ó 10 tamanhos √ó 5 rounds)
- **Opera√ß√µes testadas**: Inser√ß√£o, Busca e Remo√ß√£o

### üìä M√©tricas Coletadas

Cada estrutura √© instrumentada para coletar as seguintes m√©tricas:

#### üîç M√©tricas de Efici√™ncia Algor√≠tmica
- **`comparisons`**: N√∫mero total de compara√ß√µes realizadas
- **`node_visits`**: Quantidade de n√≥s/elementos visitados
- **`probes`**: Tentativas de acesso (espec√≠fico para hash tables)

#### ‚è±Ô∏è M√©tricas de Tempo
- **`wall_time_ms`**: Tempo total de execu√ß√£o (milissegundos)
- **`proc_time_ms`**: Tempo de processamento da CPU (milissegundos)

#### üíæ M√©tricas de Mem√≥ria
- **`mem_moves`**: Movimenta√ß√µes de dados na mem√≥ria
- **`mem_accesses`**: Total de acessos √† mem√≥ria

#### üîß M√©tricas Espec√≠ficas para Hash Tables
- **`hash_collisions`**: N√∫mero de colis√µes detectadas
- **`hash_bucket_len_after`**: Tamanho da lista ap√≥s inser√ß√£o (encadeamento)
- **`probes`**: Tentativas de acesso aos buckets
- **`load_factor`**: Fator de carga (N/M) da tabela hash

## üéÆ Processo de Execu√ß√£o

### 1Ô∏è‚É£ Fase de Prepara√ß√£o
```python
# Inicializa√ß√£o das estruturas com configura√ß√µes do experimento
    estruturas = [
        ("AVL Tree", lambda: AVLTreeDS()),
        ("Hash Table M=50 poly31", lambda: HashTableDS(M=50, hash_fn='poly31')),
        ("Hash Table M=100 poly31", lambda: HashTableDS(M=100, hash_fn='poly31')),
        ("Hash Table M=150 poly31", lambda: HashTableDS(M=150, hash_fn='poly31')),
        ("Hash Table M=50 fnv1a", lambda: HashTableDS(M=50, hash_fn='fnv1a')),
        ("Hash Table M=100 fnv1a", lambda: HashTableDS(M=100, hash_fn='fnv1a')),
        ("Hash Table M=150 fnv1a", lambda: HashTableDS(M=150, hash_fn='fnv1a')),
        ("Hash Table M=50 djb2", lambda: HashTableDS(M=50, hash_fn='djb2')),
        ("Hash Table M=100 djb2", lambda: HashTableDS(M=100, hash_fn='djb2')),
        ("Hash Table M=150 djb2", lambda: HashTableDS(M=150, hash_fn='djb2')),
        ("Array LinkedList Unsorted", lambda: ArrayLinkedList()),
        ("Array LinkedList Sorted", lambda: ArrayLinkedList(sorted_insert=True))
    ]
```

### 2Ô∏è‚É£ Fase de Execu√ß√£o
Para cada combina√ß√£o de (estrutura, tamanho, round):

1. **Gera√ß√£o de dados**: Cria√ß√£o de dataset aleat√≥rio √∫nico
2. **Opera√ß√µes sequenciais**:
   - Inser√ß√£o de todos os elementos
   - Busca por elementos existentes e inexistentes
   - Remo√ß√£o de elementos selecionados
3. **Coleta de m√©tricas**: Registro autom√°tico via framework `OpRecord`

### 3Ô∏è‚É£ Fase de An√°lise
```python
# Agrega√ß√£o estat√≠stica dos dados coletados
df_summary = BaseDataStructure.rounds_summary_df(
    structures=lista_estruturas,
    metrics=['comparisons', 'node_visits', 'wall_time_ms'],
    agg='sum',
    op_filter=('insert', 'search', 'remove')
)
```

## üìà Visualiza√ß√µes Geradas

O experimento produz **gr√°ficos individuais por m√©trica**, facilitando a compara√ß√£o direta entre estruturas:

### üìä Gr√°ficos Principais (Todas as Estruturas)

**1. Compara√ß√µes** - Opera√ß√µes: Inser√ß√£o + Busca + Remo√ß√£o
- Compara o n√∫mero total de compara√ß√µes realizadas por cada estrutura
- Revela a efici√™ncia algor√≠tmica das diferentes implementa√ß√µes

**2. Visitas de N√≥s** - Opera√ß√µes: Inser√ß√£o + Busca + Remo√ß√£o  
- Mede quantos elementos/n√≥s foram acessados durante as opera√ß√µes
- Importante para an√°lise de complexidade espacial

**3. Tempo de Execu√ß√£o (ms)** - Opera√ß√µes: Inser√ß√£o + Busca + Remo√ß√£o
- Tempo total de parede medido durante a execu√ß√£o
- M√©trica pr√°tica para performance real

**4. Movimenta√ß√µes de Mem√≥ria** - Opera√ß√µes: Inser√ß√£o + Busca + Remo√ß√£o
- Conta movimenta√ß√µes e realoca√ß√µes de dados na mem√≥ria
- Impacto direto na performance do sistema

**5. Tempo de CPU (ms)** - Opera√ß√µes: Inser√ß√£o + Busca + Remo√ß√£o
- Tempo de processamento efetivo da CPU
- Exclui tempo de espera do sistema

### üîç Gr√°ficos de An√°lise Espec√≠fica

**6. Compara√ß√µes - Inser√ß√µes**
- Foca exclusivamente na efici√™ncia de inser√ß√£o
- Revela diferen√ßas na constru√ß√£o das estruturas

**7. Compara√ß√µes - Buscas**
- Analisa apenas opera√ß√µes de busca
- Crucial para aplica√ß√µes com muitas consultas

### ‚ö° Gr√°ficos Espec√≠ficos - Hash Tables

Gerados apenas para as **9 varia√ß√µes de Hash Tables** do experimento:

**8. Colis√µes de Hash**
- N√∫mero total de colis√µes detectadas
- Compara efic√°cia entre diferentes fun√ß√µes hash (poly31, fnv1a, djb2)
- Mostra impacto do tamanho da tabela (M=50, M=100, M=150)

**9. Tamanho dos Buckets ap√≥s Inser√ß√£o**
- Comprimento das listas ligadas em cada bucket ap√≥s inser√ß√µes
- Evidencia como diferentes fun√ß√µes hash afetam a distribui√ß√£o nos buckets

**10. Tentativas de Acesso aos Buckets**
- N√∫mero de acessos aos buckets necess√°rios para opera√ß√µes
- M√©trica direta de efici√™ncia do encadeamento separado com diferentes fun√ß√µes hash

## üîß Implementa√ß√£o T√©cnica

### Framework de Instrumenta√ß√£o
```python
class BaseDataStructure:
    def __init__(self, name: str, **params: Any):
        self.op_record = OpRecord()
        self.counters = Counters()
    
    @classmethod
    def rounds_summary_df(cls, structures, metrics=None, agg='sum', op_filter=('insert',)):
        """Gera DataFrame agregado com estat√≠sticas entre rounds de m√∫ltiplas estruturas"""
        # Implementa√ß√£o completa de agrega√ß√£o entre estruturas
```

### Sistema de M√©tricas
```python
class OpRecord:
    # M√©tricas de tempo e sistema
    wall_time_ms: float = 0       # Tempo total de execu√ß√£o (milissegundos)
    proc_time_ms: float = 0       # Tempo de processamento da CPU (milissegundos)
    cpu_user_ms: float = 0        # Tempo gasto executando c√≥digo do programa
    cpu_system_ms: float = 0      # Tempo gasto em opera√ß√µes do sistema
    rss_mb: float = 0             # Quantidade de mem√≥ria RAM ocupada (MB)
    tracemalloc_peak_kb: float = 0 # Pico de mem√≥ria alocada pelo Python (KB)
    
    # M√©tricas de efici√™ncia algor√≠tmica
    comparisons: int = 0          # Compara√ß√µes realizadas
    node_visits: int = 0          # N√≥s/elementos visitados
    probes: int = 0              # Tentativas de acesso
    swaps: int = 0               # Trocas de posi√ß√£o entre elementos
    shifts: int = 0              # Deslocamentos de elementos na mem√≥ria
    rotations: int = 0           # Rota√ß√µes para balancear √°rvore
    mem_moves: int = 0           # Total de movimenta√ß√µes de dados na mem√≥ria
    
    # M√©tricas espec√≠ficas para hash tables
    hash_collisions: int = 0      # Colis√µes de hash detectadas
    hash_bucket_len_after: int = 0 # Tamanho do bucket ap√≥s inser√ß√£o
    hash_cluster_len: int = 0     # Comprimento do cluster percorrido
    hash_displacement: int = 0    # Dist√¢ncia da posi√ß√£o ideal
```

### Gera√ß√£o de Gr√°ficos
```python
class GraficosMetricas:
    def plotar_metricas_estruturas(self, structures, metrics, agg='sum'):
        """Gera gr√°ficos comparativos usando matplotlib/seaborn"""
        # Configura√ß√£o autom√°tica de layout
        # Suporte a m√∫ltiplas m√©tricas simultaneamente
        # Exporta√ß√£o em alta resolu√ß√£o
```

## üìã Resultados Esperados

### Hip√≥teses a Serem Testadas

1. **AVL Tree**: Deve apresentar performance logar√≠tmica consistente para todas as opera√ß√µes
2. **Hash Tables - Efeito da Fun√ß√£o Hash**: Diferentes fun√ß√µes hash (poly31, fnv1a, djb2) devem mostrar varia√ß√£o na distribui√ß√£o e colis√µes
3. **Hash Tables - Efeito do Tamanho**: Tabelas maiores devem ter menos colis√µes e melhor performance
4. **Fun√ß√£o Hash poly31**: Performance balanceada para strings, boa distribui√ß√£o geral
5. **Fun√ß√£o Hash fnv1a**: Excelente distribui√ß√£o, baixas colis√µes, otimizada para velocidade
6. **Fun√ß√£o Hash djb2**: Performance r√°pida, amplamente testada, boa para strings curtas
7. **Array Linked Lists**: Performance linear, com vers√£o ordenada superior em buscas mas inferior em inser√ß√µes

### M√©tricas de Interesse

- **Escalabilidade**: Como as m√©tricas crescem com o tamanho
- **Consist√™ncia**: Varia√ß√£o entre diferentes rounds
- **Trade-offs**: Rela√ß√£o entre diferentes m√©tricas (tempo vs. mem√≥ria)

## üöÄ Execu√ß√£o do Experimento

Para executar o experimento completo:

```bash
cd trab01
python rodar_experimento.py
```

### Sa√≠da Esperada
```
ÔøΩ INICIANDO EXPERIMENTO COMPLETO DE ESTRUTURAS DE DADOS
============================================================
Arquivos removidos da pasta de gr√°ficos: 0
ÔøΩ Configura√ß√£o do experimento:
  - 9 estruturas diferentes
  - [1000, 2000, 3000, 4000, 5000, 6000, 7000, 8000, 9000, 10000]
  - 5 rounds por configura√ß√£o
  - Total: 450 execu√ß√µes

üîß ESTRUTURA 1/9: AVL Tree
  üìè N = 1,000 elementos
    üîÑ Round 1/5 [0.2%]
    üîÑ Round 2/5 [0.4%]
    ...
    
üìà GERANDO GR√ÅFICOS COMPARATIVOS...
üìä Gerando gr√°ficos individuais por m√©trica...
  1. Compara√ß√µes...
  2. Visitas de N√≥s...
  3. Tempo de Execu√ß√£o (ms)...
  4. Movimenta√ß√µes de Mem√≥ria...
  5. Tempo de CPU (ms)...
üìä Gerando gr√°ficos espec√≠ficos por opera√ß√£o...
  6. Compara√ß√µes em Inser√ß√µes...
  7. Compara√ß√µes em Buscas...
üìä Gerando gr√°ficos espec√≠ficos para Hash Tables...
  8. Colis√µes de Hash...
  9. Comprimento de Clusters...
  10. Tentativas de Sondagem...

üéâ EXPERIMENTO CONCLU√çDO COM SUCESSO!
üìà Gr√°ficos gerados: 10 (um por m√©trica)
üìÅ Verifique a pasta './graficos' para ver todos os arquivos gerados
```

## üìÅ Arquivos Gerados

- **Gr√°ficos**: `./graficos/` - Visualiza√ß√µes individuais em PNG de alta resolu√ß√£o (um por m√©trica)
- **Dados**: Estruturas mant√™m hist√≥rico completo de todas as execu√ß√µes
- **Logs**: Output detalhado do processo de execu√ß√£o

## üéØ Conclus√µes Esperadas

Este experimento fornece uma base s√≥lida para:

1. **Sele√ß√£o de estruturas** adequadas para diferentes cen√°rios
2. **Otimiza√ß√£o de performance** baseada em m√©tricas reais
3. **Compreens√£o dos trade-offs** entre diferentes implementa√ß√µes
4. **Valida√ß√£o emp√≠rica** de complexidades te√≥ricas
5. **An√°lise do impacto das fun√ß√µes hash** na performance e distribui√ß√£o com encadeamento separado
6. **Compara√ß√£o entre diferentes fun√ß√µes hash** com encadeamento separado

### üìä Insights Esperados por M√©trica

**Gr√°ficos Principais (Todas as Estruturas):**
- **Compara√ß√µes**: AVL Tree deve mostrar crescimento logar√≠tmico; Hash Tables eficientes com tabelas grandes
- **Visitas de N√≥s**: Array Lists mostrar√£o crescimento linear; AVL Tree logar√≠tmico
- **Tempo de Execu√ß√£o**: Hash Tables grandes devem superar outras estruturas em opera√ß√µes mistas
- **Movimenta√ß√µes de Mem√≥ria**: Array Lists ter√£o mais movimenta√ß√µes em inser√ß√µes ordenadas
- **Tempo de CPU**: Correla√ß√£o direta com complexidade algor√≠tmica de cada estrutura

**An√°lises Espec√≠ficas:**
- **Inser√ß√µes**: Array Lists n√£o-ordenadas mais r√°pidas; ordenadas mais custosas
- **Buscas**: AVL Tree e Hash Tables superiores; Array Lists lineares

**Hash Tables Espec√≠ficas:**
- **Colis√µes**: Tabelas maiores (M=150) com menos colis√µes que pequenas (M=50)
- **Efeito da Fun√ß√£o Hash**: fnv1a deve ter menos colis√µes; poly31 performance equilibrada; djb2 rapidez
- **Buckets**: Encadeamento separado mostra listas ligadas; diferentes fun√ß√µes hash afetam distribui√ß√£o
- **Acessos**: Efici√™ncia de acesso aos buckets varia com diferentes fun√ß√µes hash
- **Compara√ß√£o entre Fun√ß√µes Hash**: Trade-offs entre velocidade, distribui√ß√£o e qualidade do hash com encadeamento separado
- **Array Linked Lists**: Demonstra√ß√£o clara da diferen√ßa entre inser√ß√£o ordenada vs. n√£o-ordenada

---

*Experimento desenvolvido como parte do estudo comparativo de estruturas de dados, implementando framework completo de instrumenta√ß√£o e an√°lise visual com foco na compara√ß√£o de fun√ß√µes hash usando encadeamento separado (chaining).*

