# Adiciona o diret√≥rio atual ao path
import sys, os
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from util_estrutura import AVLTreeDS, HashTableDS, ArrayLinkedList, BaseDataStructure
from util_graficos import GraficosMetricas
from time import time
import json

"""
ESTRUTURAS TESTADAS:
- AVL Tree (balanceada e n√£o balanceada)
- Hash Tables com 3 tamanhos (M=100, 1000, 5000) e 3 fun√ß√µes hash (poly31, fnv1a, djb2)
  usando encadeamento separado (chaining) para resolu√ß√£o de colis√µes
- Array Linked Lists (ordenada e n√£o-ordenada)
"""

# Gera dados com diferentes tamanhos
TAMANHOS = [1000, 5000, 10000, 50000, 100000]
M_HASH_TABLE = [100,1000,5000]
N_ROUNDS = 5
PASTA_ROUNDS = './rounds'
os.makedirs(PASTA_ROUNDS, exist_ok=True)

def gerar_experimento_completo():
    """
    Gera experimento completo comparando diferentes estruturas de dados
    com {N_ROUNDS} rounds para cada configura√ß√£o N √ó estrutura.
    """
    print("üî¨ INICIANDO EXPERIMENTO COMPLETO DE ESTRUTURAS DE DADOS")
    print("=" * 60)
    GraficosMetricas.limpar_pasta_graficos()
    
    # Lista para armazenar todas as estruturas com dados coletados
    lista_metricas = []
    
    # Defini√ß√£o das estruturas a serem testadas
    estruturas = [
        ("AVL Tree balanceada", lambda: AVLTreeDS(balanced=True)),
        ("AVL Tree n√£o balanceada", lambda: AVLTreeDS(balanced=False)),
        ("Array LinkedList N√£o ordenado", lambda: ArrayLinkedList(sorted_insert=False)),
        ("Array LinkedList Ordenado", lambda: ArrayLinkedList(sorted_insert=True))
    ]
    for h in M_HASH_TABLE:
        estruturas.append((f"Hash Table M={h} poly31", lambda h=h: HashTableDS(M=h, hash_fn='poly31')))
        estruturas.append((f"Hash Table M={h} fnv1a", lambda h=h: HashTableDS(M=h, hash_fn='fnv1a')))
        estruturas.append((f"Hash Table M={h} djb2", lambda h=h: HashTableDS(M=h, hash_fn='djb2')))
    
    # Para debug/testes r√°pidos: descomente a linha abaixo para testar apenas AVL Trees
    # com par√¢metro debug, roda o experimento r√°pido
    if '-debug' in sys.argv:
        print("‚ö†Ô∏è Modo DEBUG ativado: executando experimento r√°pido com apenas 2 estruturas e 2 tamanhos")
        global N_ROUNDS, TAMANHOS
        N_ROUNDS = 2
        TAMANHOS = [1000, 5000]
        estruturas = estruturas[:3]  # Apenas as 2 AVL Trees e 1 ArrayLinkedList

    if '-limpar' in sys.argv:
        print("‚ö†Ô∏è Limpar cache: remove m√©tricas antigas na pasta rounds")
        for f in os.listdir(PASTA_ROUNDS):
            if f.endswith('.json'):
                os.remove(os.path.join(PASTA_ROUNDS, f))
        print("   ‚úÖ Cache limpo com sucesso!")
    
    print(f"üìä Configura√ß√£o do experimento:")
    print(f"  - {len(estruturas)} estruturas diferentes")
    print(f"  - 2 AVL Trees (balanceada e n√£o-balanceada)")
    print(f"  - {3*len(M_HASH_TABLE)} Hash Tables: {len(M_HASH_TABLE)} tamanhos de M {M_HASH_TABLE} √ó 3 fun√ß√µes hash (poly31,fnv1a,djb2)")
    print(f"    usando encadeamento separado (chaining) para resolu√ß√£o de colis√µes")
    print(f"  - 2 Array Linked Lists (ordenada e n√£o-ordenada)")
    print(f"  - {len(TAMANHOS)} tamanhos: {TAMANHOS}")
    print(f"  - {N_ROUNDS} rounds por configura√ß√£o")
    print(f"  - Total: {len(estruturas) * len(TAMANHOS) * N_ROUNDS} execu√ß√µes")
    print()

    
    # Coleta dados para todas as combina√ß√µes
    total_execucoes = len(estruturas) * len(TAMANHOS) * N_ROUNDS
    execucao_atual = 0
    
    for i, (nome_estrutura, factory_estrutura) in enumerate(estruturas):
        print(f"üîß ESTRUTURA {i+1}/{len(estruturas)}: {nome_estrutura}")
        
        for n in TAMANHOS:
            print(f"  üìè N = {n:,} elementos")

            # verifica se todos os rounds est√£o em disco e usa os dados carregados
            gerar_arq_metricas = lambda rn,nm, _n:os.path.join(PASTA_ROUNDS,f'metrics_{nm.replace(" ","_")}_N{_n}_round{rn}.json')
            metricas_disco = []
            for round_num in range(N_ROUNDS):
                arq_metricas = gerar_arq_metricas(round_num, nome_estrutura, n)
                if os.path.exists(arq_metricas):
                    print(f"    ‚úÖ Round {round_num+1}/{N_ROUNDS} | {nome_estrutura} N = {n} | [j√° existente, carregando...]")
                    # Carrega m√©tricas do arquivo JSON
                    try:
                        with open(arq_metricas, 'r') as f:
                            metricas_json = json.load(f)
                        metricas_disco.append(metricas_json)
                    except Exception as e:
                        print(f"    ‚ùå Erro ao carregar {arq_metricas}: {e}")
                        metricas_disco = []
                        break
                else:
                    metricas_disco = []
                    break

            if len(metricas_disco) == N_ROUNDS:
                print(f"    üéâ Todos os {N_ROUNDS} rounds j√° existem em disco. Usando dados carregados.")
                lista_metricas.extend(metricas_disco)
                continue  # pula para o pr√≥ximo tamanho n
            
            for round_num in range(N_ROUNDS):
                execucao_atual += 1
                progresso = (execucao_atual / total_execucoes) * 100
                
                print(f"    üîÑ Round {round_num+1}/{N_ROUNDS} | {nome_estrutura} N = {n} | [{progresso:.1f}%]")
                
                # Cria nova inst√¢ncia da estrutura
                estrutura:BaseDataStructure = factory_estrutura()
                estrutura.clear_log()  # Limpa logs anteriores
                                
                # Executa opera√ß√µes
                estrutura.carregar_dados(n)        # INSERTs
                estrutura.buscar_dados(n // 4)     # SEARCHs (25% do total)
                estrutura.remover_dados(n // 10)   # REMOVEs (10% do total)
                estrutura.descarregar_dados()      # retira o dataset da mem√≥ria
                
                # Adiciona √† lista
                metricas = estrutura.export_metrics_json()
                # Salva m√©tricas em arquivo JSON para poss√≠vel reuso futuro
                arq_metricas = gerar_arq_metricas(round_num, nome_estrutura, n)
                try:
                    with open(arq_metricas, 'w') as f:
                        json.dump(metricas, f, indent=2)
                    print(f"      üíæ M√©tricas salvas em {arq_metricas}")
                except Exception as e:
                    print(f"      ‚ùå Erro ao salvar m√©tricas em {arq_metricas}: {e}")
                    exit(1)
                lista_metricas.append(metricas)
    
    print("\n‚úÖ Coleta de dados conclu√≠da!")
    print(f"üìä {len(lista_metricas)} estruturas prontas para an√°lise")
    
    return lista_metricas, estruturas

def gerar_graficos_comparativos(lista_metricas):
    """
    Gera gr√°ficos comparativos com um gr√°fico por m√©trica.
    Cada gr√°fico compara todas as estruturas para uma √∫nica m√©trica.
    """
    print("\nüìà GERANDO GR√ÅFICOS COMPARATIVOS...")
    print("=" * 40)
    
    # Converte estruturas para o formato de m√©tricas JSON ou utiliza as que foram recuperadas
   
    gm = GraficosMetricas()
    caminhos_gerados = []
    
    # Defini√ß√£o das m√©tricas principais para todas as estruturas
    metricas_principais = [
        ('comparisons', 'Compara√ß√µes', ('insert', 'search', 'remove')),
        ('node_visits', 'Visitas de N√≥s (√Årvores/Listas)', ('insert', 'search', 'remove')),
        ('wall_time_ms', 'Tempo de Execu√ß√£o (ms)', ('insert', 'search', 'remove')),
        ('mem_moves', 'Movimenta√ß√µes de Mem√≥ria', ('insert', 'search', 'remove')),
        ('proc_time_ms', 'Tempo de CPU (ms)', ('insert', 'search', 'remove'))
    ]
    
    # Gera um gr√°fico por m√©trica principal
    print("üìä Gerando gr√°ficos individuais por m√©trica...")
    for i, (metrica, titulo_metrica, operacoes) in enumerate(metricas_principais, 1):
        for escala in ['linear', 'log']:
            print(f"  {i}. {titulo_metrica}. {escala}...")
            
            # Filtra m√©tricas para estruturas que suportam esta m√©trica
            metricas_filtradas = []
            for metrica_json in lista_metricas:
                # Verifica se a m√©trica json alguma estrutura correspondente ignora esta m√©trica
                if metrica not in metrica_json.get('metrics_out',[]):
                   metricas_filtradas.append(metrica_json)
            
            # Gera gr√°fico comparativo para esta m√©trica
            caminho = gm.plotar_metricas(
                metrics_data=metricas_filtradas,
                metrics=[metrica],  # Uma m√©trica por gr√°fico
                agg='sum',
                escala=escala,
                op_filter=operacoes,
                titulo_personalizado=f'{titulo_metrica} - Compara√ß√£o entre Estruturas'
            )
            caminhos_gerados.append(caminho)
    
    # M√©tricas espec√≠ficas para an√°lise detalhada de opera√ß√µes
    print("üìä Gerando gr√°ficos espec√≠ficos por opera√ß√£o...")
    
    for escala in ['linear', 'log']:
        print(f"  5. Tempo de Execu√ß√£o (ms). {escala}...")
        caminho_time = gm.plotar_metricas(
            metrics_data=lista_metricas,
            metrics=['wall_time_ms'],
            agg='sum',
            escala=escala,
            op_filter=('insert', 'search', 'remove'),
            titulo_personalizado='Tempo de Execu√ß√£o (ms) - Todas as Opera√ß√µes'
        )
        caminhos_gerados.append(caminho_time)
        # An√°lise espec√≠fica de inser√ß√µes
        print(f"  6. Compara√ß√µes em Inser√ß√µes. {escala}...")
        caminho_insert = gm.plotar_metricas(
            metrics_data=lista_metricas,
            metrics=['comparisons'],
            agg='sum',
            escala=escala,
            op_filter=('insert',),
            titulo_personalizado='Compara√ß√µes - Opera√ß√µes de Inser√ß√£o'
        )
        caminhos_gerados.append(caminho_insert)
        
        # An√°lise espec√≠fica de buscas
        print(f"  7. Compara√ß√µes em Buscas. {escala}...")
        caminho_search = gm.plotar_metricas(
            metrics_data=lista_metricas,
            metrics=['comparisons'],
            agg='sum',
            escala=escala,
            op_filter=('search',),
            titulo_personalizado='Compara√ß√µes - Opera√ß√µes de Busca'
        )
        caminhos_gerados.append(caminho_search)
    
        # Separar m√©tricas de estruturas hash para an√°lise espec√≠fica
        hash_metricas = []
        for metrica_json in lista_metricas:
            # Verifica se √© uma estrutura hash
            if 'HashTable' in metrica_json.get('ds_name', ''):
                hash_metricas.append(metrica_json)
        
        # Gr√°ficos espec√≠ficos para Hash Tables (se existirem)
        if hash_metricas:
            print(f"üìä Gerando gr√°ficos espec√≠ficos para Hash Tables.{escala}...")
            
            # M√©tricas espec√≠ficas de hash tables
            metricas_hash = [
                ('hash_collisions', 'Colis√µes de Hash', ('insert', 'search')),
                ('hash_bucket_len_after', 'Tamanho dos Buckets ap√≥s Inser√ß√£o', ('insert',)),
                ('probes', 'Tentativas de Acesso aos Buckets', ('insert', 'search'))
            ]
            
            for j, (metrica_hash, titulo_hash, ops_hash) in enumerate(metricas_hash, 8):
                print(f"  {j}. {titulo_hash}...")
                
                # Gera gr√°fico espec√≠fico para hash tables
                caminho_hash = gm.plotar_metricas(
                    metrics_data=hash_metricas,  # Apenas m√©tricas de hash tables
                    metrics=[metrica_hash],
                    agg='sum',
                    escala=escala,
                    op_filter=ops_hash,
                    titulo_personalizado=f'{titulo_hash} - Hash Tables'
                )
                caminhos_gerados.append(caminho_hash)
    
    return caminhos_gerados

# Execu√ß√£o principal
if __name__ == "__main__":
    inicio = time()
    # limpando pasta de gr√°ficos antigos
    GraficosMetricas.limpar_pasta_graficos()
    # Gera experimento
    lista_metricas, estruturas = gerar_experimento_completo()
    
    # Gera gr√°ficos
    caminhos = gerar_graficos_comparativos(lista_metricas)

    print("\nüéâ EXPERIMENTO CONCLU√çDO COM SUCESSO!")
    print("=" * 50)
    print("üìà Gr√°ficos gerados:")
    for i, caminho in enumerate(caminhos, 1):
        print(f"  {i}. {caminho}")
    
    print(f"\nüìÅ Verifique a pasta './graficos' para ver todos os arquivos gerados")
    print(f"üìä Total de estruturas analisadas: {len(lista_metricas)}")
    
    # Estat√≠sticas do experimento
    print(f"\nüìã ESTAT√çSTICAS DO EXPERIMENTO:")
    print(f"  - Estruturas testadas: {len(estruturas)}")
    print(f"    ‚Ä¢ 2 AVL Trees (balanceada e n√£o-balanceada)")
    print(f"    ‚Ä¢ {3*len(M_HASH_TABLE)} Hash Tables ({len(M_HASH_TABLE)} valores de M {M_HASH_TABLE} √ó 3 fun√ß√µes hash) usando encadeamento separado")
    print(f"    ‚Ä¢ 2 Array Linked Lists")
    print(f"  - Tamanhos testados: {len(TAMANHOS)} {TAMANHOS}")
    print(f"  - Rounds por configura√ß√£o: {N_ROUNDS}")
    print(f"  - Total de execu√ß√µes: {len(lista_metricas)}")
    print(f"  - Gr√°ficos gerados: {len(caminhos)} (um por m√©trica)")
    print(f"  - M√©tricas principais: {len(caminhos)} gr√°ficos comparando todas as estruturas")   
    print('|' * 80)
    print(f'Tempo de gera√ß√£o do experimento: {time() - inicio:.2f} segundos')
    
    print("\nObrigado por utilizar o framework de experimentos de estruturas de dados do grupo 5!")